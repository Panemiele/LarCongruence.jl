<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Introduzione · LarCongruence.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.044/juliamono.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/LAR_Congruence.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="LarCongruence.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../">LarCongruence.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Introduzione</a><ul class="internal"><li><a class="tocitem" href="#Matrici-Sparse"><span>Matrici Sparse</span></a></li><li><a class="tocitem" href="#Semiring"><span>Semiring</span></a></li><li class="toplevel"><a class="tocitem" href="#GraphBLAS"><span>GraphBLAS</span></a></li><li class="toplevel"><a class="tocitem" href="#Lar-Congruence"><span>Lar Congruence</span></a></li><li><a class="tocitem" href="#SIMD"><span>SIMD</span></a></li><li><a class="tocitem" href="#Tasks"><span>Tasks</span></a></li><li><a class="tocitem" href="#Threads"><span>Threads</span></a></li></ul></li><li><a class="tocitem" href="../grafoDipendenze/">Grafo delle dipendenze</a></li><li><a class="tocitem" href="../sviluppo/">Sviluppo</a></li><li><span class="tocitem">Codice Sorgente e funzioni</span><ul><li><a class="tocitem" href="../documentazioni/verticesCongruence/">Vertices Congruence</a></li><li><a class="tocitem" href="../documentazioni/sparseMatrix/">Sparse Matrix</a></li><li><a class="tocitem" href="../documentazioni/graphBLAS/">GraphBLAS</a></li><li><a class="tocitem" href="../documentazioni/arrayOfArrays/">Array of Arrays</a></li></ul></li><li><span class="tocitem">Esempi e risultati</span><ul><li><a class="tocitem" href="../esempi/">Esempi</a></li><li><a class="tocitem" href="../risultati/">Risultati e prestazioni</a></li></ul></li><li><a class="tocitem" href="../authors/">Autori</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Introduzione</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Introduzione</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/Panemiele/LarCongruence.jl/blob/main/docs/src/theory.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><p>In questa sezione, verranno introdotti i principali concetti matematici e tecnologici utilizzati all&#39;interno del progetto LarCongruence.jl.</p><h2 id="Matrici-Sparse"><a class="docs-heading-anchor" href="#Matrici-Sparse">Matrici Sparse</a><a id="Matrici-Sparse-1"></a><a class="docs-heading-anchor-permalink" href="#Matrici-Sparse" title="Permalink"></a></h2><p>In analisi numerica, una matrice sparsa è una matrice i cui valori sono quasi tutti uguali a zero. I pochi valori presenti sono distribuiti in modo casuale, cioè non si concentrano in determinate aree specifiche (Cluster).</p><h2 id="Semiring"><a class="docs-heading-anchor" href="#Semiring">Semiring</a><a id="Semiring-1"></a><a class="docs-heading-anchor-permalink" href="#Semiring" title="Permalink"></a></h2><p>Un Semiring è una struttura algebrica che generalizza l&#39;aritmetica reale rimpiazzando (+,·) con l&#39;operazione binaria (Op1, Op2). Un Semiring, in GraphBLAS, viene definito come l&#39;unione di un <strong>monoide M</strong> e un <strong>operatore</strong> binario moltiplicativo F};</p><ul><li>Il monoide è una struttura algebrica formata da un operatore binario <strong>associativo</strong> e commutativo di tipo additivo} e da <strong>un dominio D</strong> che deve contenere anche un elemento vuoto (simbolo dell&#39;operatore: ⊕);</li><li>L&#39;operatore binario F è formato invece da <strong>due domini di input</strong> e <strong>un dominio di output</strong> (simbolo dell&#39;operatore: ⊗).</li></ul><h1 id="GraphBLAS"><a class="docs-heading-anchor" href="#GraphBLAS">GraphBLAS</a><a id="GraphBLAS-1"></a><a class="docs-heading-anchor-permalink" href="#GraphBLAS" title="Permalink"></a></h1><p>GraphBLAS è la libreria che offre funzioni per matrici sparse, la più comune quando si parla di calcolo parallelo e distribuito. Questa libreria offre metodi smart ed efficaci per memorizzare valori ed effettuare operazioni su di essi all&#39;interno di matrici sparse. Si può scegliere di implementare GraphBLAS sia sulla CPU che su GPU (la cosa interessante delle GPU è che lo si può fare in parallelo). Si usano le matrici per rappresentare i grafi, in modo da poter utilizzare le operazioni dell&#39;algebra lineare che sono molto veloci da eseguire: il prodotto fra matrici, per esempio, permette di ricavare informazioni sui percorsi possibili e nodi vicini. GraphBLAS utilizza oggetti matematici chiamati &quot;Semirings&quot; che permettono di implementare qualsiasi operatore matematico e definire così un nuovo modello di prodotto matriciale. Due esempi:</p><ul><li>Plus-times: tipico prodotto matriciale</li><li>Tropical Semiring: usa i seguenti operatori:<ul><li>interno: la somma</li><li>esterno: il valore minimo</li></ul></li></ul><h1 id="Lar-Congruence"><a class="docs-heading-anchor" href="#Lar-Congruence">Lar Congruence</a><a id="Lar-Congruence-1"></a><a class="docs-heading-anchor-permalink" href="#Lar-Congruence" title="Permalink"></a></h1><p>E&#39; una libreria che ha l&#39;obiettivo di eseguire la congruenza di celle e complessi di catene locali. Sono disponibili tre implementazioni di LarCongruence:</p><ul><li>Julia Native Sparse Matrix</li><li>Array of Arrays</li><li>GraphBLAS - estende il funzionamento di GraphBLAS, oltre che ai grafi, anche ai complessi cellulari.</li></ul><p>Per calcolare la congruenza di complessi di catena locali si procede come segue: </p><ul><li>Per ogni faccia, si costruisce il suo complesso di catene locale, cioè la partizione del piano bidimensionale (identificato con z=0) indotta dal bordo di quella faccia e da tutte le altre che la dividono. </li><li>Si rimette assieme per calcolare la congruenza: dall&#39;insieme di complessi di catene locali ad ognuna delle facce dell&#39;input, bisogna arrivare ad un unico complesso, &quot;incollando&quot; fra loro in modo coerente i vari complessi locali.</li></ul><p>Si noti che l&#39;operazione che può essere parallelizzata è la prima, questo perché viene eseguita in modo indipendente per ciascuna delle facce.</p><h2 id="SIMD"><a class="docs-heading-anchor" href="#SIMD">SIMD</a><a id="SIMD-1"></a><a class="docs-heading-anchor-permalink" href="#SIMD" title="Permalink"></a></h2><p><strong>Single Instruction, Multiple Data (SIMD)</strong> è un metodo per parallelizzare i calcoli all&#39;interno della CPU, per cui una singola operazione viene eseguita su più elementi di dati contemporaneamente. Le moderne architetture della CPU contengono set di istruzioni che possono farlo, operando su molti variabili contemporaneamente. Questo non rende ogni ciclo più veloce. In particolare, si noti che l&#39;utilizzo di SIMD implica che l&#39;ordine delle operazioni all&#39;interno e attraverso il ciclo potrebbe cambiare. Il compilatore deve essere certo che il riordino sia sicuro prima che tenti di parallelizzare un ciclo</p><h2 id="Tasks"><a class="docs-heading-anchor" href="#Tasks">Tasks</a><a id="Tasks-1"></a><a class="docs-heading-anchor-permalink" href="#Tasks" title="Permalink"></a></h2><p>Un <strong>Task</strong> è semplicemente un insieme di istruzioni che possono essere sospese e riprese in qualsiasi momento all&#39;interno di quell&#39;insieme. Una funzione può anche essere pensata come un insieme di istruzioni, e quindi di attività può essere visto come qualcosa di simile. Ma ci sono due differenze fondamentali:</p><ul><li>Non c&#39;è overhead per passare da un Task all&#39;altro, il che significa che non viene riservato spazio nello stack per un cambio;</li><li>a differenza di una funzione che deve terminare prima che il controllo torni al chiamante, un Task può essere interrotto e il controllo può essere passato a un altro Task in molti momenti diversi durante la sua esecuzione. In altre parole, nelle attività non esiste una relazione gerarchica chiamante-chiamato. Questo da l&#39;impressione di lavorare in parallelo.</li></ul><h2 id="Threads"><a class="docs-heading-anchor" href="#Threads">Threads</a><a id="Threads-1"></a><a class="docs-heading-anchor-permalink" href="#Threads" title="Permalink"></a></h2><p>I <strong>Thread</strong> sono sequenze di calcolo che possono essere eseguite indipendentemente su un core della CPU, contemporaneamente ad altre sequenze simili. A differenza dei task, che sono leggeri, i thread devono memorizzare uno stato quando vengono scambiati. Così, mentre si possono avere centinaia o migliaia di task in esecuzione, è opportuno avere solamente un numero limitato di Thread, tipicamente pari al numero di core della macchina in uso.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../grafoDipendenze/">Grafo delle dipendenze »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.19 on <span class="colophon-date" title="Tuesday 28 June 2022 12:01">Tuesday 28 June 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
